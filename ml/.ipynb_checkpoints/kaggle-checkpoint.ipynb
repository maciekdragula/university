{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "        \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import emoji\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('politicians-and-celebrities/contest_tweets_2.csv_trainset.csv', index_col=[\"N\"])\n",
    "test = pd.read_csv('politicians-and-celebrities/testset_notarget.csv', index_col=[\"id\"])\n",
    "train_corpus = []\n",
    "for index, row in train.iterrows():\n",
    "    text = row[0]\n",
    "    emo = list(set(emoji.get_emoji_regexp().findall(text)))\n",
    "    text += ' '.join([emoji.demojize(e) for e in emo])\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    train_corpus.append(text)\n",
    "train_corpus = np.array(train_corpus)\n",
    "train_target = train['target'].to_numpy()\n",
    "\n",
    "test_corpus = []\n",
    "for index, row in test.iterrows():\n",
    "    text = row[0]\n",
    "#     text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "#     emo = list(set(emoji.get_emoji_regexp().findall(text)))\n",
    "#     text += ' '.join([emoji.demojize(e) for e in emo])\n",
    "    test_corpus.append(text)\n",
    "test_corpus = np.array(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "#     ('vect', CountVectorizer(strip_accents='unicode', analyzer='word', stop_words='english')),\n",
    "    ('vect', CountVectorizer()),\n",
    "#     ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(class_prior=[0.61, 0.004, 0.18, 0.013], alpha=0.005, fit_prior=False)),\n",
    "#     ('clf', MultinomialNB(class_prior=[0.25, 0.25, 0.25, 0.25], alpha=0.005, fit_prior=False)),\n",
    "#     ('clf', MultinomialNB(alpha=0.05)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(train_corpus, train_target, test_size=0.3)\n",
    "text_clf.fit(train_corpus, train_target)\n",
    "predicted = text_clf.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'politician': 3024,\n",
       "         'celebrity': 3111,\n",
       "         'internetplatform': 3126,\n",
       "         'biz&tech': 3163})"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.csv', 'w') as f:\n",
    "    i  = 0\n",
    "    f.write('\"id\",\"target\"\\n')\n",
    "    for w in predicted:\n",
    "        f.write(str(i) + ',\"' + w + '\"\\n')\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['internetplatform', 'celebrity', 'internetplatform', 'politician',\n",
       "       'celebrity'], dtype='<U16')"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[4823:4828]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"RT @SpaceX: Cargo is offloaded and spacecraft is powered down. #Dragon back in its nest after about 5 weeks at the @Space_Station http://t.\\\\xe2\\\\x80\\\\xa6'\",\n",
       "       '“@hcc23: @jtimberlake I hear we share a fav movie. \"You touch me, I yell rat... There\\'s another phone around here somewhere, find it!\"',\n",
       "       'Hi. https://t.co/11Fyyf5IQm',\n",
       "       'I’ve watched every moment of political conventions since 1984. Tonight I left early. I was afraid. https://t.co/Td9Uf0iVqt #RNCinCLE',\n",
       "       \"@ShakirasSmile I will show Milan how much affection he's getting today from all of you!! Shak\"],\n",
       "      dtype='<U260')"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus[4823:4828]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3106.0"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
